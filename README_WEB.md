# üåê Interface Web - PornX Scraper

Interface web moderna para gerenciar o scraping e visualizar dados coletados.

## üöÄ Iniciar Servidor

```bash
npm run server
```

O servidor estar√° dispon√≠vel em: **http://localhost:3000**

## üì± P√°ginas Dispon√≠veis

### 1. P√°gina Inicial
**URL:** `http://localhost:3000`

P√°gina de boas-vindas com acesso r√°pido √†s funcionalidades.

### 2. Dashboard
**URL:** `http://localhost:3000/dashboard.html`

**Funcionalidades:**
- ‚úÖ Configurar n√∫mero de p√°ginas para scraping (1-100)
- ‚úÖ Escolher entre salvar no banco de dados ou em JSON
- ‚úÖ Iniciar scraping com um clique
- ‚úÖ Acompanhar progresso em tempo real
- ‚úÖ Visualizar logs do scraping
- ‚úÖ Estat√≠sticas gerais (total de modelos, v√≠deos, fotos)

**Como usar:**
1. Defina o n√∫mero de p√°ginas
2. Marque/desmarque "Salvar no banco de dados"
3. Clique em "Iniciar Scraping"
4. Acompanhe o progresso nos logs

### 3. Visualizar Modelos
**URL:** `http://localhost:3000/models.html`

**Funcionalidades:**
- ‚úÖ Grid visual com todas as modelos coletadas
- ‚úÖ Imagem de capa de cada modelo
- ‚úÖ Nome, quantidade de v√≠deos e fotos
- ‚úÖ Link direto para o perfil da modelo
- ‚úÖ Pagina√ß√£o (20 modelos por p√°gina)
- ‚úÖ Estat√≠sticas em tempo real
- ‚úÖ Atualiza√ß√£o autom√°tica a cada 30 segundos

## üîå API Endpoints

### GET `/api/models`
Retorna lista de modelos com pagina√ß√£o.

**Query Parameters:**
- `page` (opcional): N√∫mero da p√°gina (padr√£o: 1)
- `limit` (opcional): Itens por p√°gina (padr√£o: 20)

**Resposta:**
```json
{
  "success": true,
  "data": {
    "models": [...],
    "pagination": {
      "page": 1,
      "limit": 20,
      "total": 100,
      "totalPages": 5
    },
    "stats": {
      "total_videos": "5000",
      "total_photos": "500",
      "avg_videos": "50.00",
      "avg_photos": "5.00"
    }
  }
}
```

### POST `/api/scrape/start`
Inicia o processo de scraping.

**Body:**
```json
{
  "pages": 5,
  "useDatabase": true
}
```

**Resposta:**
```json
{
  "success": true,
  "message": "Scraping iniciado para 5 p√°gina(s)",
  "useDatabase": true
}
```

### GET `/api/scrape/status`
Retorna status atual do scraping.

**Resposta:**
```json
{
  "success": true,
  "isRunning": true,
  "logs": [
    {
      "type": "info",
      "message": "Iniciando scraping...",
      "timestamp": "2026-01-28T06:30:00.000Z"
    }
  ]
}
```

### GET `/api/stats`
Retorna estat√≠sticas gerais.

**Resposta:**
```json
{
  "success": true,
  "stats": {
    "total_models": "100",
    "total_videos": "5000",
    "total_photos": "500",
    "avg_videos": "50.00",
    "avg_photos": "5.00",
    "last_scrape": "2026-01-28T06:30:00.000Z"
  }
}
```

### DELETE `/api/models/:id`
Remove uma modelo do banco de dados.

**Resposta:**
```json
{
  "success": true,
  "message": "Modelo removida com sucesso"
}
```

## ‚öôÔ∏è Configura√ß√£o

### Vari√°veis de Ambiente

Adicione no arquivo `.env`:

```env
PORT=3000
```

### Requisitos

- ‚úÖ Node.js 18+
- ‚úÖ PostgreSQL (para funcionalidade completa)
- ‚úÖ Depend√™ncias instaladas (`npm install`)

## üé® Recursos da Interface

### Design Moderno
- Gradiente roxo/azul
- Cards com sombras e anima√ß√µes
- Responsivo para mobile e desktop
- √çcones e emojis para melhor UX

### Tempo Real
- Logs atualizados automaticamente
- Status do scraping em tempo real
- Estat√≠sticas que atualizam a cada 30s

### Facilidade de Uso
- Interface intuitiva
- Feedback visual claro
- Mensagens de erro amig√°veis

## üîß Solu√ß√£o de Problemas

### Erro: "Cannot GET /"
**Solu√ß√£o:** Certifique-se de que o servidor est√° rodando com `npm run server`

### Erro: "Erro ao conectar ao banco"
**Solu√ß√£o:** 
1. Verifique se o PostgreSQL est√° rodando
2. Confirme as credenciais no arquivo `.env`
3. Execute `npm run init-db` para criar as tabelas

### Scraping n√£o inicia
**Solu√ß√£o:**
1. Verifique os logs no console do servidor
2. Certifique-se de que n√£o h√° outro scraping em execu√ß√£o
3. Reinicie o servidor

## üìä Exemplo de Uso Completo

```bash
# 1. Configurar banco de dados
npm run init-db

# 2. Iniciar servidor web
npm run server

# 3. Acessar no navegador
# http://localhost:3000

# 4. No Dashboard:
#    - Definir 10 p√°ginas
#    - Marcar "Salvar no banco de dados"
#    - Clicar em "Iniciar Scraping"

# 5. Acompanhar progresso nos logs

# 6. Ir para "Visualizar Dados" para ver resultados
```

## üöÄ Pr√≥ximos Passos

Ap√≥s coletar dados:
1. Acesse o Dashboard para ver estat√≠sticas
2. V√° para "Visualizar Dados" para explorar as modelos
3. Clique em "Ver Perfil" para acessar o perfil original
4. Execute novos scrapings conforme necess√°rio
